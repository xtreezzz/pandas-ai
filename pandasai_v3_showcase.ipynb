{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/g-emarco/notebook_host/blob/main/pandasai_v3_showcase.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PandasAI v3: The Complete Showcase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a comprehensive overview of the capabilities of PandasAI v3, covering a wide range of functions from basic setup to advanced features like agents, custom skills, and the semantic layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Basic Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandasai pandasai-litellm openpyxl pandasai-openai pandasai-google-colab pandasai-lancedb pandasai-chromadb pandasai-sql pandasai-pinecone pandasai-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasai as pai\n",
    "from pandasai_litellm.litellm import LiteLLM\n",
    "\n",
    "# 1.1 - LiteLLM and pai.config.set\n",
    "# IMPORTANT: Please add your OpenAI API key below for the notebook to run.\n",
    "llm = LiteLLM(model=\"gpt-4o-mini\", api_key=\"YOUR_OPENAI_API_KEY\")\n",
    "pai.config.set({\"llm\": llm})\n",
    "\n",
    "# 1.2 - Create a sample DataFrame and use df.to_csv\n",
    "data = {\n",
    "    'country': ['United States', 'United Kingdom', 'France', 'Germany', 'Italy', 'Spain', 'Canada', 'Australia', 'Japan', 'China'],\n",
    "    'gdp': [21.4, 2.8, 2.7, 3.8, 2.0, 1.4, 1.7, 1.4, 5.1, 14.3],\n",
    "    'happiness_index': [7.0, 7.1, 6.8, 7.2, 6.5, 6.6, 7.3, 7.2, 6.9, 5.1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('country_data.csv', index=False)\n",
    "\n",
    "# 1.3 - pai.read_csv\n",
    "countries_df = pai.read_csv('country_data.csv')\n",
    "\n",
    "# 1.4 - df.chat (string output)\n",
    "print(countries_df.chat('Which country has the highest GDP?'))\n",
    "\n",
    "# 1.5 - df.chat (dataframe output)\n",
    "print(countries_df.chat('What are the top 3 countries by happiness index?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6 - df.chat (chart output) and chart_response.save\n",
    "chart = countries_df.chat('Plot a bar chart of the GDP of the top 5 countries by happiness index.')\n",
    "chart.save('gdp_chart.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: The PandasAI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai import Agent\n",
    "\n",
    "# The v3 Agent maintains conversational context automatically.\n",
    "agent = Agent(countries_df, verbose=True) # Use verbose=True to see the generated code\n",
    "print(agent.chat('Which are the bottom 3 countries by GDP?'))\n",
    "print(agent.chat('Of these, which one has the highest happiness index?')) # No follow_up method needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Custom Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai import skill\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@skill()\n",
    "def calculate_bonus(salary: float, performance: float) -> float:\n",
    "    return salary * (performance / 100)\n",
    "\n",
    "@skill()\n",
    "def plot_salaries(names: list[str], salaries: list[float]):\n",
    "    plt.bar(names, salaries)\n",
    "    plt.show()\n",
    "\n",
    "@skill()\n",
    "def format_currency(amount: float) -> str:\n",
    "    return f'${amount:,.2f}'\n",
    "\n",
    "employee_data = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'salary': [50000, 75000, 60000],\n",
    "    'performance': [90, 85, 95]\n",
    "})\n",
    "\n",
    "employee_agent = Agent(employee_data)\n",
    "employee_agent.add_skills(calculate_bonus, plot_salaries, format_currency)\n",
    "print(employee_agent.chat('What is the bonus for Alice?'))\n",
    "print(employee_agent.chat('Plot the salaries of the employees.'))\n",
    "print(employee_agent.chat('What is the total salary formatted as currency?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: LLMs and Database Connectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai.llm import OpenAI, AzureOpenAI\n",
    "from pandasai.connectors import SqliteConnector, PostgreSQLConnector\n",
    "\n",
    "# Using a functional in-memory SQLite connector\n",
    "sqlite_connector = SqliteConnector(table='countries', database=':memory:')\n",
    "countries_df.to_sql('countries', sqlite_connector.engine, index=False)\n",
    "db_agent = Agent(sqlite_connector)\n",
    "print(db_agent.chat('Which country has the highest GDP?'))\n",
    "\n",
    "# Conceptual examples for other connectors\n",
    "openai_llm = OpenAI(api_key=\"YOUR_OPENAI_API_KEY\")\n",
    "azure_llm = AzureOpenAI(deployment_name=\"YOUR_DEPLOYMENT_NAME\", api_key=\"YOUR_AZURE_API_KEY\", api_base=\"YOUR_AZURE_ENDPOINT\")\n",
    "pg_connector = PostgreSQLConnector(host='localhost', database='test_db', user='user', password='password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Vector Stores and Agent Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai.ee.vectorstores import LanceDB, ChromaDB, Pinecone, Qdrant\n",
    "\n",
    "# Using LanceDB\n",
    "lancedb_store = LanceDB()\n",
    "lance_agent = Agent(countries_df, vectorstore=lancedb_store)\n",
    "lance_agent.train(queries=[\"What is the happiest country?\"], codes=[\"print(df.sort_values(by='happiness_index', ascending=False).iloc[0]['country'])\"])\n",
    "print(lance_agent.chat(\"What is the happiest country?\"))\n",
    "\n",
    "# Conceptual examples for other vector stores\n",
    "pinecone_store = Pinecone(api_key=\"YOUR_PINECONE_API_KEY\")\n",
    "qdrant_store = Qdrant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Secure Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandasai-docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai_docker import DockerSandbox\n",
    "\n",
    "sandbox = DockerSandbox()\n",
    "sandbox.start()\n",
    "safe_agent = Agent(countries_df, sandbox=sandbox)\n",
    "result = safe_agent.chat('Plot a histogram of the happiness index.')\n",
    "result.show() # Use result.show() to display the plot from the sandbox\n",
    "sandbox.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: The Semantic Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p my-org/datasets\n",
    "semantic_df = pai.create(\n",
    "    path=\"my-org/datasets/countries\",\n",
    "    df=countries_df,\n",
    "    description=\"Data about countries, including GDP and happiness index.\"\n",
    ")\n",
    "\n",
    "loaded_df = pai.load(\"my-org/datasets/countries\")\n",
    "print(pai.chat('What is the GDP of the happiest country based on the loaded dataset?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Legacy v2 Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai.smart_dataframe import SmartDataframe\n",
    "from pandasai.smart_datalake import SmartDatalake\n",
    "\n",
    "smart_df = SmartDataframe(countries_df, config={\"llm\": llm})\n",
    "print(smart_df.chat('Which country has the lowest happiness index?'))\n",
    "\n",
    "# The explain(), clarification_questions(), and rephrase_query() methods are part of the legacy SmartDataframe.\n",
    "# In the v3 Agent, you can get similar information by using `verbose=True` during Agent initialization to see the generated code.\n",
    "print(f'Explanation:\\n{smart_df.explain()}\\n')\n",
    "print(f'Clarification Questions:\\n{smart_df.clarification_questions(\"give me the top countries by gdp\")}\\n')\n",
    "print(f'Rephrased Query:\\n{smart_df.rephrase_query(\"give me the top countries by gdp\")}\\n')\n",
    "\n",
    "lake = SmartDatalake([countries_df], config={\"llm\": llm})\n",
    "print(lake.chat('What is the total GDP of all countries combined?'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
