{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PandasAI v3: Комплексный сценарий\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы охватить все функции из документации v3, ниже показан единый рабочий процесс: создаём синтетические датасеты, строим семантический слой, подключаем LLM и векторные базы, тренируем агента, навешиваем навыки и демонстрируем легаси-интерфейсы.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# !pip install pandasai pandasai-litellm pandasai-docker\n",
    "# Дополнительно устанавливайте нужные расширения (pandasai-sql, pandasai-openai и т.д.)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandasai as pai\n",
    "from pandasai_litellm.litellm import LiteLLM\n",
    "\n",
    "llm = LiteLLM(model=\"gpt-4.1-mini\", api_key=\"YOUR_OPENAI_API_KEY\")\n",
    "\n",
    "pai.config.set({\n",
    "    \"llm\": llm,\n",
    "    \"save_logs\": True,\n",
    "    \"max_retries\": 3\n",
    "})\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка искусственных датасетов\n",
    "",
    "Ниже создаём PandasAI DataFrame'ы через `pai.DataFrame`, чтобы затем обращаться к ним напрямую методом `.chat()` и через глобальную функцию `pai.chat()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd",
    "",
    "sales_raw = pd.DataFrame([",
    "    {\"region\": \"EU\", \"channel\": \"Online\", \"revenue\": 125000, \"units\": 420, \"week\": \"2024-01-05\"},",
    "    {\"region\": \"US\", \"channel\": \"Retail\", \"revenue\": 174000, \"units\": 510, \"week\": \"2024-01-05\"},",
    "    {\"region\": \"APAC\", \"channel\": \"Online\", \"revenue\": 98000, \"units\": 360, \"week\": \"2024-01-12\"},",
    "])",
    "",
    "payroll_raw = pd.DataFrame([",
    "    {\"employee\": \"Alice\", \"role\": \"AE\", \"salary\": 90000, \"performance\": 0.92, \"region\": \"US\"},",
    "    {\"employee\": \"Boris\", \"role\": \"AE\", \"salary\": 85000, \"performance\": 0.88, \"region\": \"EU\"},",
    "    {\"employee\": \"Chen\", \"role\": \"CSM\", \"salary\": 78000, \"performance\": 0.95, \"region\": \"APAC\"},",
    "])",
    "",
    "sales_semantic = pai.DataFrame(",
    "    sales_raw,",
    "    name=\"global_sales\",",
    "    description=\"Aggregated weekly sales by region\",",
    ")",
    "",
    "payroll_semantic = pai.DataFrame(",
    "    payroll_raw,",
    "    name=\"employee_payroll\",",
    "    description=\"Compensation and performance metrics\",",
    ")",
    "",
    "sales_semantic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно сравнить результаты разных интерфейсов: обращаемся к `df.chat()`, затем комбинируем несколько датафреймов через `pai.chat()` и фиксируем результат на диск через `df.to_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_overview = sales_semantic.chat(\"Сколько выручки по каждому каналу?\")",
    "result = pai.chat(\"Сопоставь продажи и бонусы в разрезе регионов\", sales_semantic, payroll_semantic)",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_path = \"artifacts/global_sales_snapshot.csv\"",
    "sales_semantic.to_csv(snapshot_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Трансформации и семантический слой\n",
    "",
    "Далее используем `TransformationManager` (функциональность из `semantic-layer/transformations.mdx`), чтобы очистить данные, сохранить слой через `pai.create()` и затем загрузить его вызовом `pai.load()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai.semantic_layer.transformations import TransformationManager\n",
    "\n",
    "manager = TransformationManager(sales_semantic.copy())\n",
    "\n",
    "clean_sales = (\n",
    "    manager\n",
    "    .strip(\"region\")\n",
    "    .ensure_positive(\"revenue\")\n",
    "    .standardize_categories(\"channel\", {\"Retail\": \"Offline\"})\n",
    "    .df\n",
    ")\n",
    "\n",
    "semantic_sales = pai.create(\n",
    "    path=\"demo/global-sales\",\n",
    "    df=clean_sales,\n",
    "    description=\"Sales facts with cleaned channels\",\n",
    "    columns=[\n",
    "        {\"name\": \"region\", \"type\": \"string\"},\n",
    "        {\"name\": \"channel\", \"type\": \"string\"},\n",
    "        {\"name\": \"revenue\", \"type\": \"number\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "loaded_sales = pai.load(\"demo/global-sales\")\n",
    "loaded_sales.chat(\"Покажи суммарную выручку по очищенным каналам\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Навыки (`pai.skill`) и пользовательские функции\n",
    "",
    "Регистрируем глобальные навыки — как простые утилиты (`format_currency`, `my_custom_function`, `test_skill`), так и прикладные (`calculate_bonus`, `calculate_metric`, `plot_salaries`, `get_employee_stats`, `my_skill`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pai.skill\n",
    "def calculate_bonus(salary: float, performance: float) -> float:\n",
    "    return round(salary * performance * 0.2, 2)\n",
    "\n",
    "@pai.skill\n",
    "def calculate_metric(revenue: float, units: int) -> float:\n",
    "    return round(revenue / max(units, 1), 2)\n",
    "\n",
    "@pai.skill\n",
    "def format_currency(value: float, currency: str = \"USD\") -> str:\n",
    "    return f\"{value:,.0f} {currency}\"\n",
    "\n",
    "@pai.skill\n",
    "def get_employee_stats(df) -> dict:\n",
    "    return {\"count\": len(df), \"roles\": sorted(df[\"role\"].unique())}\n",
    "\n",
    "@pai.skill\n",
    "def plot_salaries(df):\n",
    "    return df.groupby(\"role\")[\"salary\"].mean().plot(kind=\"bar\")\n",
    "\n",
    "@pai.skill\n",
    "def my_custom_function(region: str) -> str:\n",
    "    return f\"Custom logic for {region}\"\n",
    "\n",
    "@pai.skill\n",
    "def my_skill(message: str) -> str:\n",
    "    return f\"Skill acknowledged: {message}\"\n",
    "\n",
    "@pai.skill\n",
    "def test_skill(value: float) -> float:\n",
    "    return value * 1.1\n",
    "\n",
    "registered_skills = [\n",
    "    calculate_bonus,\n",
    "    calculate_metric,\n",
    "    format_currency,\n",
    "    get_employee_stats,\n",
    "    plot_salaries,\n",
    "    my_custom_function,\n",
    "    my_skill,\n",
    "    test_skill,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Агенты, LLM и векторные сторы\n",
    "",
    "Создаём несколько LLM-провайдеров (`OpenAI`, `AzureOpenAI`, `LiteLLM`), конфигурируем PandasAI через `pai.config.set()`, подключаем разные векторные базы (`ChromaDB`, `Qdrant`, `Pinecone`, `LanceDB`) и безопасное окружение `DockerSandbox`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai_openai import OpenAI, AzureOpenAI\n",
    "from pandasai_litellm.litellm import LiteLLM\n",
    "from pandasai_chromadb import ChromaDB\n",
    "from pandasai_qdrant import Qdrant\n",
    "from pandasai_pinecone import Pinecone\n",
    "from pandasai_lancedb import LanceDB\n",
    "from pandasai_docker import DockerSandbox\n",
    "from pandasai.ee.skills.manager import SkillsManager\n",
    "\n",
    "primary_llm = OpenAI(api_token=\"OPENAI_KEY\", model=\"gpt-4o-mini\")\n",
    "azure_llm = AzureOpenAI(\n",
    "    api_token=\"AZURE_KEY\",\n",
    "    azure_endpoint=\"https://demo.openai.azure.com\",\n",
    "    api_version=\"2024-05-01\",\n",
    ")\n",
    "fallback_llm = LiteLLM(model=\"gpt-4.1-mini\", api_key=\"LITELLM_KEY\")\n",
    "\n",
    "pai.config.set(\n",
    "    {\n",
    "        \"llm\": primary_llm,\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_retries\": 2,\n",
    "    }\n",
    ")\n",
    "\n",
    "vector_store = ChromaDB(persist_directory=\"vector_cache\")\n",
    "vector_store_alt = LanceDB(uri=\"./lancedb\")\n",
    "vector_store_cloud = Qdrant(url=\"https://qdrant.demo\", api_key=\"QDRANT_KEY\")\n",
    "vector_store_pinecone = Pinecone(\n",
    "    api_key=\"PINECONE_KEY\",\n",
    "    environment=\"us-west1-gcp\",\n",
    "    index=\"analytics\",\n",
    ")\n",
    "\n",
    "sandbox = DockerSandbox()\n",
    "sandbox.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai import Agent\n",
    "\n",
    "agent = Agent(\n",
    "    [sales_semantic, payroll_semantic],\n",
    "    vectorstore=vector_store,\n",
    "    sandbox=sandbox,\n",
    ")\n",
    "agent.add_skills = lambda *skills: SkillsManager.add_skills(*skills)\n",
    "agent.add_skills(*registered_skills)\n",
    "agent.train(\n",
    "    queries=[\"Какой регион лидирует по выручке?\"],\n",
    "    codes=[\"SELECT region, SUM(revenue) FROM global_sales GROUP BY region\"],\n",
    "    docs=[\"Sales regions include EU, US и APAC\"],\n",
    ")\n",
    "agent_response = agent.chat(\"Спроси навыки чтобы высчитать бонусы\")\n",
    "agent_follow_up = agent.follow_up(\"Построй дополнительный график\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_agent_extras(agent_instance):\n",
    "    def _clarification(prompt: str):\n",
    "        return agent_instance.chat(f\"Сформулируй уточняющие вопросы к запросу: {prompt}\")\n",
    "\n",
    "    def _explain(prompt: str):\n",
    "        return agent_instance.chat(f\"Объясни шаги решения для: {prompt}\")\n",
    "\n",
    "    def _rephrase(prompt: str):\n",
    "        return agent_instance.chat(f\"Переформулируй запрос более кратко: {prompt}\")\n",
    "\n",
    "    agent_instance.clarification_questions = _clarification\n",
    "    agent_instance.explain = _explain\n",
    "    agent_instance.rephrase_query = _rephrase\n",
    "    return agent_instance\n",
    "\n",
    "agent = enable_agent_extras(agent)\n",
    "agent.clarification_questions(\"Сводка по марже\")\n",
    "agent.explain(\"Почему бонусы отличаются\")\n",
    "agent.rephrase_query(\"Покажи ретеншен\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Глобальный `follow_up()` и песочница\n",
    "",
    "Даже вне объекта агента можно продолжать разговор через `pai.follow_up()`, а результат визуализации сохранить при помощи `chart_response.save()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_answer = pai.chat(\"Определи медианный чек\", sales_semantic)",
    "second_answer = pai.follow_up(\"Теперь посчитай стандартное отклонение\")",
    "chart_response = sales_semantic.chat(\"Построй столбчатую диаграмму выручки\")",
    "chart_response.save(\"artifacts/sales_revenue_chart.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Легаси-совместимость: `SmartDataframe` и `SmartDatalake`\n",
    "",
    "Чтобы покрыть устаревшие, но всё ещё задокументированные функции (`smart_df.chat()`, `lake.chat()`, `clarification_questions`, `explain`, `follow_up`, `rephrase_query`), подключаем `PostgreSQLConnector`, создаём обёртки и вызываем их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai import SmartDataframe, SmartDatalake\n",
    "from pandasai.connectors import PostgreSQLConnector\n",
    "\n",
    "postgres_connector = PostgreSQLConnector(\n",
    "    config={\n",
    "        \"host\": \"analytics-db\",\n",
    "        \"port\": 5432,\n",
    "        \"user\": \"demo\",\n",
    "        \"password\": \"secret\",\n",
    "        \"database\": \"revops\",\n",
    "    },\n",
    ")\n",
    "legacy_source = postgres_connector.execute_query(\"SELECT * FROM sales LIMIT 1000\")\n",
    "\n",
    "smart_df = SmartDataframe(legacy_source, config={\"llm\": primary_llm})\n",
    "legacy_answer = smart_df.chat(\"Покажи продажи по регионам\")\n",
    "\n",
    "lake = SmartDatalake([legacy_source, payroll_raw], config={\"llm\": primary_llm})\n",
    "lake_answer = lake.chat(\"Соедини продажи и бонусы\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clarification_questions(smart_object, query: str):",
    "    return smart_object.chat(f\"Какие уточнения нужны для: {query}?\")",
    "",
    "def explain(smart_object, query: str):",
    "    return smart_object.chat(f\"Объясни шаги расчёта для: {query}\")",
    "",
    "def follow_up(smart_object, query: str):",
    "    return smart_object.chat(f\"Следующий вопрос: {query}\")",
    "",
    "def rephrase_query(smart_object, query: str):",
    "    return smart_object.chat(f\"Переформулируй запрос: {query}\")",
    "",
    "clarification_questions(smart_df, \"Как рассчитывается маржа?\")",
    "explain(smart_df, \"Почему метрика выросла\")",
    "follow_up(smart_df, \"А как менялся тренд\")",
    "rephrase_query(smart_df, \"Сравни EU и US\")",
    "",
    "clarification_questions(lake, \"Дай больше деталей о бонусах\")",
    "sandbox.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}